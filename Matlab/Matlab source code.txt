
filename = "Clear.xlsx";
clear = readtable(filename,'TextType','string');
head(clear)

filename = "covid010420.xlsx";
covid = readtable(filename,'TextType','string');
head(covid)

data=[clear;covid] %merge datasets


data.Var1=randsample(data.Var1,height(data)) % shuffle datasets
data=sortrows(data,"Var1")
data(:,'Var1') = []
head(data)

writetable(data,"covid_clear_dataset.csv")

idx = strlength(data.description) == 0;
data(idx,:) = []; %remove rows with empty description

data.event_type = categorical(data.event_type); %convert the labels in the event_type column of the table to categorical
figure
h = histogram(data.event_type);%view labels distribution using a histogram
xlabel("Class")
ylabel("Frequency")
title("Class Distribution")

cvp = cvpartition(data.event_type,'Holdout',0.1); %Partition the data into a training partition and a held-out test set
dataTrain = data(cvp.training,:);
dataTest = data(cvp.test,:);

%Extract the text data and labels from the tables.
textDataTrain = dataTrain.description;
textDataTest = dataTest.description;
YTrain = dataTrain.event_type;
YTest = dataTest.event_type;

documents = preprocessing(textDataTrain)

bag = bagOfWords(documents)

bag = removeInfrequentWords(bag,2); %Remove words from the bag-of-words model that do not appear more than two times
[bag,idx] = removeEmptyDocuments(bag);
YTrain(idx) = [];
bag

%Train a supervised classification model using the word frequency counts from the bag-of-words model and the labels.
XTrain = bag.Counts;
mdl = fitcecoc(XTrain,YTrain,'Learners','linear')

%Predict the labels of the test data using the trained model and calculate the classification accuracy.
documentsTest = preprocessing(textDataTest);
XTest = encode(bag,documentsTest);

YPred = predict(mdl,XTest);
acc = sum(YPred == YTest)/numel(YTest)

%str = [ ...
 %   "A large tree is downed and blocking traffic outside Apple Hill."
  %  "Damage to many car windshields in parking lot."
   % "Lots of water damage to computer equipment inside the office."
    %"The number of coronavirus cases in Italy has reached 86,498, according to a tally by researchers at Johns Hopkins University. That puts the European country ahead of China, where 81,946 infections have been confirmed. Both are short of the over 104,000 cases reported in the United States. However not all countries report or measure cases in the same manner, so the true figures could be higher in Italy and China. More than 9,000 people have died from the coronavirus in Italy, more than anywhere else in the world, followed by Spain at 5,138 deaths, and China at 3,295. In the US, there have been about 1,700 deaths so far, according to the Johns Hopkins tally. Italy had 969 deaths on Friday -- the biggest single-day jump since the crisis began. The country's health system has been pushed to the brink by the outbreak, especially in the north, which has seen the highest concentration of cases."
    %"The COVID-19 number of cases in Italy has reached 86,498, according to a tally by researchers at Johns Hopkins University. That puts the European country ahead of China, where 81,946 infections have been confirmed. Both are short of the over 104,000 cases reported in the United States. However not all countries report or measure cases in the same manner, so the true figures could be higher in Italy and China. More than 9,000 people have died from the in Italy, more than anywhere else in the world, followed by Spain at 5,138 deaths, and China at 3,295. In the US, there have been about 1,700 deaths so far, according to the Johns Hopkins tally. Italy had 969 deaths on Friday -- the biggest single-day jump since the crisis began. The country's health system has been pushed to the brink by the outbreak, especially in the north, which has seen the highest concentration of cases."];

filename = "rawdata.csv";
str = readtable(filename,'TextType','string');
head(str)

documentsNew = preprocessing(str.description);
XNew = encode(bag,documentsNew);
str.sentiment = predict(mdl,XNew)
str(:,'description') = []
writetable(str,"sentiments.csv")

function documents = preprocessing(textData)

% Tokenize the text.
documents = tokenizedDocument(textData);



% Remove a list of stop words then lemmatize the words. To improve
% lemmatization, first use addPartOfSpeechDetails.
documents = addPartOfSpeechDetails(documents);
words = ["(CNN)"];
documents = removeWords(documents,words);
documents = removeStopWords(documents);
documents = normalizeWords(documents,'Style','lemma');

% Erase punctuation.
documents = erasePunctuation(documents);

% Remove words with 2 or fewer characters, and words with 15 or more
% characters.
documents = removeShortWords(documents,2);
documents = removeLongWords(documents,15);

end